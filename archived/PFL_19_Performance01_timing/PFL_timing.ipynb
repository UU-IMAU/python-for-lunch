{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from time import time as rt_timer\n",
    "from datetime import datetime as rt_clock\n",
    "from time import sleep\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Python for Lunch (PFL) - Performance Sessions - Time & Time Measurements \n",
    "\n",
    "# _What on Earth is wrong with Time ?_ \n",
    "\n",
    "This *Python for Lunch (PFL)* series shall introduce you, as the audience, to some general concepts in performance optimisation.\n",
    "\n",
    "*Performance optimisation* in programming tries to answer the simple question: \n",
    "**How can I improve the design and code of my program so it performs its tasks as rapidly and efficiently as possible, \n",
    "given the modern hardware capabilities available to me ?**\n",
    "\n",
    "In popular and social discussions with *technology enthusiasts*, some people of you may have heard already terms such as \n",
    "*GPU Computing*, *Vectorisation* and the use of *(Just-in-Time) C-Kernels*, in the context of improving the performance \n",
    "of (Python) programs. How could you make use of those technologies ? Also, and more importantly, does it even make sense \n",
    "to investigate how to use those technologies (i.e. techniques) for your application ? Those are the kind of questions we \n",
    "want to answer in this PFL series.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Before actually doing some performance optimisation, we first need to understand how we can measure the performance of \n",
    "our current program. It's like writing a scientific article: having a fancy new idea is nice, but \n",
    "you first need to investigate the current state of research before pointing out which gap is being addressed by your \n",
    "new idea. In the realm of *high-performance computing (HPC)* and software programs, performance is measured by the passing\n",
    "of *time* for executing a piece of code (i.e. program runtime). As we will see today, what sounds so simple (i.e. *measuring time*) \n",
    "can actually be quite difficult, if done correctly, and is often done incorrectly outside the computer sciences.\n",
    "\n",
    "### Time and the *reference frame*\n",
    "\n",
    "Let's start of by doing a few little thought experiments on time. In the first case, we imagine we sit at our desk and we get a \n",
    "notification that a new MS Teams meeting is starting in 10 minutes. This notification is is fairly unambiguous: you can set an alarm\n",
    "on your watch for in-10-minutes. These 10 minutes refer to the passing of our real-world time, so for a digital watch - no matter\n",
    "on which device it runs, if it is networked or used my millions of people - we expect it to behave just as our manual wrist watch. In\n",
    "other terms, we have an *absolute reference frame* here - which is the real-world UTC time.\n",
    "\n",
    "Another case of time is the communication between GPS satellites and their GPS base stations: Both the base stations as well as\n",
    "the satellite are running high-precision clocks and exchange to time measurements in high-precision in a satellite message. The\n",
    "base stations (as: our end-user devices) receive the *time-pings* from the satellite. Base on the time difference between the \n",
    "satellite ping and the local clock, together with the base station triangulation, we can calculate the (triangular, barycentric)\n",
    "position of any receiver. The time measurements in this case are in a *relative reference frame* - time passing relative to the \n",
    "satellite.\n",
    "\n",
    "We can encounter another relative reference frame in daily life in the train: When you board the train, it shows you on the digital\n",
    "dashboard the travel time from you current- to your target location. During the travel, several delays can occur, suchs as\n",
    "congestion, rail change, and so forth. When you arrive at your target destimation, and you measured the real-world time passed\n",
    "for the travel, then the latter measurement will be larger than what was initially displayed. Now, the question is: what was the\n",
    "actual travel time ? Was it the real-world time passing between you boarding the train and you arriving, or the accumulated time(steps)\n",
    "the train was actually _moving_ on rails toward the destination ? This latter measurement is also a relative reference frame - a\n",
    "time measurement that is relative to the motion of the train. And this case is also similar to what we encounter in computing when\n",
    "measuring time.\n",
    "\n",
    "### Our introduction example: How to measure 100ms on a computer ?\n",
    "\n",
    "As a starting point in measuring time, we start off with a simple task:\n",
    "\n",
    "**Measure the passing of a 100ms during code execution**\n",
    "\n",
    "This task seems mundane, perhaps very abstract, as you can say: well, I just start a counter, put my program to sleep \n",
    "for 0.1 second, and then take the counter again - and 100ms have passed! \n",
    "\n",
    "Well, this is _not_ the case. It's the difference between *defining* PI in a program via its calculator value (i.e. 3.141592654) \n",
    "and *calculating* PI via Monte Carlo sampling.\n",
    "\n",
    "The following function code measure the passing of 100ms using two (seamingly different) timing modes, by doing the following:\n",
    "- run a global loop to measure 10 sec (to be resilient to measurement outliers)\n",
    "- within that global loop, obtain a start time *t(0)*\n",
    "- check if the difference between the current time *t(x)* and the start time *t(0)* is greater-or-equal-to 0.1s\n",
    "- if that is the case, the current time becomes the end measurement *t(n)*\n",
    "- we compute *delta(t(n), t(0))*, which is then ideally exactly 0.1s\n",
    "- for the next measurement cycle, we set *t(0) = t(n)*\n",
    "- for statistical evaluation, we log *delta(t(n), t(0))*\n",
    "- if *t(x) - t(0) < 0.1s*, we do nothing (i.e. we wait for a fraction of 100ms before checking again)\n",
    "\n",
    "The expected outcome of this test:\n",
    "- *delta(t(n), t(0))* is always exactly 0.1s\n",
    "- *delta(t(n), t(0))* is always the same, for both timing modes and all individual 100ms-intervals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------\n",
      "'dt' via real-world global timer:  0.1004894\n",
      "'dt' via real-world global clock:  0.1004910\n",
      "abs_delta(timer, clock):  0.0000016\n",
      "abs_delta(timer, definitive dt=100ms):  0.0004894\n",
      "abs_delta(clock, definitive dt=100ms):  0.0004910\n",
      "--------------------------------------------------------------\n",
      "Statistical comparison:\n",
      "\ttime-deltas [s]\n",
      "\t\tmin:  0.0003866\n",
      "\t\tmax:  0.0019161\n",
      "\t\tavg:  0.0009606\n",
      "\t\tstd_dev:  0.0003880\n",
      "\tclock-deltas [s]\n",
      "\t\tmin:  0.0003900\n",
      "\t\tmax:  0.0019160\n",
      "\t\tavg:  0.0009606\n",
      "\t\tstd_dev:  0.0003880\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def measure_time_simple(sync_bit=None, print_each=False):\n",
    "    current_time = rt_timer()\n",
    "    stime_rt_global = rt_timer()\n",
    "    etime_rt_global = rt_timer()\n",
    "    sclock_rt_global = rt_clock.now()\n",
    "    eclock_rt_global = rt_clock.now()\n",
    "    rt_global_stime = current_time\n",
    "    rt_clock_deltas = []\n",
    "    rt_time_deltas = []\n",
    "    \n",
    "    printed = False\n",
    "    while (current_time-rt_global_stime) < 10.0:\n",
    "        current_time = rt_timer()\n",
    "        if (current_time-stime_rt_global) >= 0.1:\n",
    "            etime_rt_global = rt_timer()\n",
    "            eclock_rt_global = rt_clock.now()\n",
    "            dt_rt_timer_global = etime_rt_global-stime_rt_global\n",
    "            dt_rt_clock_global = (eclock_rt_global-sclock_rt_global).total_seconds()\n",
    "            if print_each or not printed:\n",
    "                print(\"--------------------------------------------------------------\")\n",
    "                print(\"'dt' via real-world global timer: {:10.7f}\".format(dt_rt_timer_global))\n",
    "                print(\"'dt' via real-world global clock: {:10.7f}\".format(dt_rt_clock_global))\n",
    "                # print(\"System time clock (real-world time): {}\".format(eclock_rt_global))\n",
    "                print(\"abs_delta(timer, clock): {:10.7f}\".format(math.fabs(dt_rt_timer_global-dt_rt_clock_global)))\n",
    "            rt_time_deltas.append( math.fabs(dt_rt_timer_global-0.1) )\n",
    "            rt_clock_deltas.append( math.fabs(dt_rt_clock_global-0.1) )\n",
    "            if print_each or not printed:\n",
    "                print(\"abs_delta(timer, definitive dt=100ms): {:10.7f}\".format(rt_time_deltas[-1]))\n",
    "                print(\"abs_delta(clock, definitive dt=100ms): {:10.7f}\".format(rt_clock_deltas[-1]))\n",
    "                print(\"--------------------------------------------------------------\")\n",
    "            stime_rt_global = etime_rt_global\n",
    "            sclock_rt_global = eclock_rt_global\n",
    "            printed = True\n",
    "        sleep(0.02)\n",
    "    \n",
    "    time_deltas = numpy.array(rt_time_deltas)\n",
    "    clock_deltas = numpy.array(rt_clock_deltas)\n",
    "    print(\"Statistical comparison:\")\n",
    "    print(\"\\ttime-deltas [s]\")\n",
    "    print(\"\\t\\tmin: {:10.7f}\".format(time_deltas.min()))\n",
    "    print(\"\\t\\tmax: {:10.7f}\".format(time_deltas.max()))\n",
    "    print(\"\\t\\tavg: {:10.7f}\".format(time_deltas.mean()))\n",
    "    print(\"\\t\\tstd_dev: {:10.7f}\".format(time_deltas.std()))\n",
    "    print(\"\\tclock-deltas [s]\")\n",
    "    print(\"\\t\\tmin: {:10.7f}\".format(clock_deltas.min()))\n",
    "    print(\"\\t\\tmax: {:10.7f}\".format(clock_deltas.max()))\n",
    "    print(\"\\t\\tavg: {:10.7f}\".format(clock_deltas.mean()))\n",
    "    print(\"\\t\\tstd_dev: {:10.7f}\".format(clock_deltas.std()))\n",
    "    if sync_bit is not None:\n",
    "        sync_bit.set()\n",
    "    return True\n",
    "\n",
    "result = measure_time_simple()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the results, we can conclude the following: definitive timing of 100 ms (or less) not attainable with the \n",
    "method we used (i.e. the clocks and time modules). This may be because they have a too small resolution to be applicable \n",
    "to our case. If this hythesis holds true, the above-used timing tools *time.time()* and *datetime.datetime.now()* provide \n",
    "fraudulent timings when doing performance measurements.\n",
    "\n",
    "In order to prove the hypothesis, we need further testing. For that, we assess the influence of *concurrent processes* \n",
    "(i.e. other processes running simultaneously on the computer aside the time simulation). The expected result is as follows:\n",
    "\n",
    "- if the timing stays the same while having other background processes running, the time modules are good - they may just lack resolution\n",
    "- if the timing differs with a larger amount of background processes, we are not measuring 100ms in our program, but we're measuring 100ms system-wide - which leads to fraudulent measurements, as there are always background programs running on any digital computing device\n",
    "\n",
    "In the example, in order to assess this, we spawn a large number of concurrent processes that do nothing else in the \n",
    "background that counting up a sum and wait for a small fraction of time."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------\n",
      "'dt' via real-world global timer:  0.1041305\n",
      "'dt' via real-world global clock:  0.1041240\n",
      "abs_delta(timer, clock):  0.0000065\n",
      "abs_delta(timer, definitive dt=100ms):  0.0041305\n",
      "abs_delta(clock, definitive dt=100ms):  0.0041240\n",
      "--------------------------------------------------------------\n",
      "Statistical comparison:\n",
      "\ttime-deltas [s]\n",
      "\t\tmin:  0.0002734\n",
      "\t\tmax:  0.0107309\n",
      "\t\tavg:  0.0011540\n",
      "\t\tstd_dev:  0.0017378\n",
      "\tclock-deltas [s]\n",
      "\t\tmin:  0.0002740\n",
      "\t\tmax:  0.0107330\n",
      "\t\tavg:  0.0011540\n",
      "\t\tstd_dev:  0.0017375\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from multiprocessing import Process, Event\n",
    "from numpy.random import default_rng\n",
    "from scipy import signal\n",
    "\n",
    "ext_delay = 0.0075\n",
    "def external_work(sync_bit):\n",
    "    a = 1\n",
    "    is_done = False\n",
    "    while not is_done:\n",
    "        sleep(ext_delay)\n",
    "        a += a\n",
    "        is_done = sync_bit.is_set()\n",
    "        \n",
    "\n",
    "sync_bit = Event()\n",
    "concurrent_processes = [Process(target=external_work, args=(sync_bit,)) for i in range(0, 300)]\n",
    "for proc in concurrent_processes:\n",
    "    proc.start()\n",
    "    \n",
    "result = measure_time_simple(sync_bit)\n",
    "    \n",
    "for proc in concurrent_processes:\n",
    "    proc.join()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What we can see from the results is that the average deviation between our target measurement (i.e. *100ms*) and our \n",
    "actual measurement grows larger, as does the standard deviation of the measurement error. In conclusion, we can say that \n",
    "with other processes running concurrently, accurate timming is becoming increasingly difficult - if not even impossible.\n",
    "\n",
    "Remember: in this example, we attempt to measure **100 ms** time steps, whereas in a realistic setup with hundreds of \n",
    "concurrent processes running, we measure on average time steps of **100 +/- 38 ms** - a measurement dilution of 38 percent!\n",
    "\n",
    "Why ? What is the culprit ? And: do we need to care ?\n",
    "\n",
    "### A physical example of performance measurement - particle tracing on flow fields\n",
    "\n",
    "Let's first design a physical example, to see if those deviations we saw in the abstract timing example actually play a \n",
    "role when estimating the performance of physics simulations. As a illustration, let's consider a simplified particle \n",
    "tracing method on flow fields."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from scipy.io import netcdf\n",
    "from scipy.interpolate import interpn\n",
    "\n",
    "class Particle():\n",
    "    \n",
    "    def __init__(self, x, y, keep_trace_history=False):\n",
    "        self._pt = numpy.array([x, y, .0])\n",
    "        self._trace_history = None\n",
    "        if keep_trace_history:\n",
    "            self._trace_history = []\n",
    "\n",
    "    def __del__(self):\n",
    "        del self._pt\n",
    "        if self._trace_history is not None:\n",
    "            del self._trace_history[:]\n",
    "\n",
    "    def advect(self, u_array, v_array, griddims, dt, fdt):\n",
    "        if self._trace_history is not None and len(self._trace_history)<1:\n",
    "            self._trace_history.append(numpy.array(self._pt))\n",
    "        lon_range = griddims[2][-1] - griddims[2][0]\n",
    "        lat_range = griddims[1][-1] - griddims[1][0]\n",
    "        pt = numpy.transpose(self._pt, (2,1,0))\n",
    "        uv = numpy.array([interpn(griddims, u_array, pt, method='linear', fill_value=.0), interpn(griddims, v_array, pt, method='linear', fill_value=.0)])\n",
    "        self._pt[0:1] += ((uv*dt) /1000.0) # particles live on a km grid\n",
    "        while self._pt[0] > griddims[2][-1]:\n",
    "            self._pt[0] -= lon_range\n",
    "        while self._pt[0] < griddims[2][0]:\n",
    "            self._pt[0] += lon_range\n",
    "\n",
    "        while self._pt[1] > griddims[1][-1]:\n",
    "            self._pt[1] -= lat_range\n",
    "        while self._pt[1] < griddims[1][0]:\n",
    "            self._pt[1] += lat_range\n",
    "        self._pt[2] += dt\n",
    "        if self._trace_history is not None:\n",
    "            self._trace_history.append(numpy.array(self._pt))\n",
    "\n",
    "    def advect_uv(self, u, v, griddims, dt, fdt):\n",
    "        if self._trace_history is not None and len(self._trace_history)<1:\n",
    "            self._trace_history.append(numpy.array(self._pt))\n",
    "        self._pt[0] = self._pt[0] + ((u*dt) /1000.0) # particles live on a km grid\n",
    "        self._pt[1] = self._pt[1] + ((v*dt) /1000.0) # particles live on a km grid\n",
    "        # -- boundary condition treatment -- #\n",
    "        if self._pt[0] > griddims[2][-1]:\n",
    "            self._pt[0] = griddims[2][-1]\n",
    "        if self._pt[0] < griddims[2][0]:\n",
    "            self._pt[0] = griddims[2][0]\n",
    "            \n",
    "        if self._pt[1] > griddims[1][-1]:\n",
    "            self._pt[1] = griddims[1][-1]\n",
    "        if self._pt[1] < griddims[1][0]:\n",
    "            self._pt[1] = griddims[1][0]\n",
    "\n",
    "        self._pt[2] += dt\n",
    "        # -- history tracing - only applicable for plotting the particle trajectories -- #\n",
    "        if self._trace_history is not None:\n",
    "            self._trace_history.append(numpy.array([self._pt[0], self._pt[1]]))\n",
    "    \n",
    "    @property\n",
    "    def pt(self):\n",
    "        return self._pt\n",
    "    \n",
    "    def point(self, tstep):\n",
    "        if self._trace_history is not None:\n",
    "            return self._trace_history[tstep]\n",
    "        return self._pt\n",
    "\n",
    "    def time_index(self, ft):\n",
    "        # expect ft to be forward-linear\n",
    "        f_dt = ft[1]-ft[0]\n",
    "        f_interp = self._pt[2] / f_dt\n",
    "        ti = int(math.floor(f_interp))\n",
    "        return ti\n",
    "\n",
    "    def time_partion(self, ft):\n",
    "        # expect ft to be forward-linear\n",
    "        f_dt = ft[1]-ft[0]\n",
    "        f_interp = self._pt[2] / f_dt\n",
    "        f_t = f_interp-math.floor(f_interp)\n",
    "        return f_t\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Simulation():\n",
    "    def __init__(self, fx, fy, ft, fu, fv, num_visual_traces=0):\n",
    "        self._data = []\n",
    "        self._fx = fx\n",
    "        self._fy = fy\n",
    "        self._ft = ft\n",
    "        self._fu = fu\n",
    "        self._fv = fv\n",
    "        self._gdims = (self._ft, self._fy, self._fx)\n",
    "        self._simtime = .0\n",
    "        self._num_visual_traces = num_visual_traces\n",
    "        \n",
    "    def __del__(self):\n",
    "        del self._data[:]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        max_item = len(self._data)-1\n",
    "        return self._data[min(item, max_item)]\n",
    "    \n",
    "    @property\n",
    "    def sim_time(self):\n",
    "        return self._simtime\n",
    "    \n",
    "    @property\n",
    "    def sim_end_time(self):\n",
    "        return self._ft[-1]\n",
    "\n",
    "    def add_particle(self, x, y):\n",
    "        keep_trace_history = False\n",
    "        if len(self._data) < self._num_visual_traces:\n",
    "            keep_trace_history = True\n",
    "        self._data.append(Particle(x, y, keep_trace_history))\n",
    "        \n",
    "    def advect_once(self, dt):\n",
    "        fdt = self._ft[1]-self._ft[0]\n",
    "        x = []\n",
    "        y = []\n",
    "        t = []\n",
    "        for p in self._data:\n",
    "            x.append(p.pt[0])\n",
    "            y.append(p.pt[1])\n",
    "            t.append(p.pt[2])\n",
    "        pts = (numpy.array(t), numpy.array(y), numpy.array(x))\n",
    "        us = interpn(self._gdims, self._fu, pts, method='linear', fill_value=.0)\n",
    "        vs = interpn(self._gdims, self._fv, pts, method='linear', fill_value=.0)\n",
    "        for i, p in enumerate(self._data):\n",
    "            #p.advect(self._fu, self._fv, self._gdims, dt, fdt)\n",
    "            p.advect_uv(us[i], vs[i], self._gdims, dt, fdt)\n",
    "        self._simtime += dt\n",
    "\n",
    "    def time_index(self):\n",
    "        if len(self._data) < 1:\n",
    "            return 0\n",
    "        return self._data[0].time_index(self._ft)\n",
    "\n",
    "    def time_partion(self):\n",
    "        if len(self._data) < 1:\n",
    "            return 0\n",
    "        return self._data[0].time_partion(self._ft)\n",
    "    \n",
    "    def time_index_value(self, tx):\n",
    "        # expect ft to be forward-linear\n",
    "        f_dt = self._ft[1]-self._ft[0]\n",
    "        f_interp = tx / f_dt\n",
    "        ti = int(math.floor(f_interp))\n",
    "        return ti\n",
    "\n",
    "    def time_partion_value(self, tx):\n",
    "        # expect ft to be forward-linear\n",
    "        f_dt = self._ft[1]-self._ft[0]\n",
    "        f_interp = tx / f_dt\n",
    "        f_t = f_interp-math.floor(f_interp)\n",
    "        return f_t\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The *Particle* and *Simulation* class are the core elements of our simulation. In true lagrangian manner though,\n",
    "we also need some flow field data on which those particles are being advected on. Those are loaded from prepared \n",
    "temporal-2D perlin-noise field sample."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3aa5e041a1c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# ==== Load flow-field data ==== #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetcdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetcdf_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'perlin.nc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mftimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'netcdf' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'netcdf' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "import os, requests\n",
    "\n",
    "if not os.path.exists('perlin.nc'):\n",
    "    data_url = \"https://surfdrive.surf.nl/files/index.php/s/T7QyLbGjaGMdnVD/download\"\n",
    "    requests.get(data_url)\n",
    "# ==== Load flow-field data ==== #\n",
    "f = netcdf.netcdf_file('perlin.nc', 'r')\n",
    "ftimes = f.variables['time'].data\n",
    "fX = f.variables['lon'].data\n",
    "fY = f.variables['lat'].data\n",
    "fU = f.variables['u'].data\n",
    "fV = f.variables['v'].data\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After now having prepared the simulation and obtained its field data, we can actually create a specific simulation. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sim = Simulation(fX, fY, ftimes, fU, fV)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us now say: we want to simulate 5000 particles with an update interval *dt=12 hours*, and measure the time it \n",
    "takes to (a) advect the particles in each simulation step (i.e. kernel runtime) and (b) complete the simulation as a \n",
    "whole (i.e total runtime)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "==== running JUST the simulation ====\n",
      "Processing at  0.1351351 percent ...\n",
      "Processing at 10.0000000 percent ...\n",
      "Processing at 20.0000000 percent ...\n",
      "Processing at 30.0000000 percent ...\n",
      "Processing at 40.0000000 percent ...\n",
      "Processing at 50.0000000 percent ...\n",
      "Processing at 60.0000000 percent ...\n",
      "Processing at 70.0000000 percent ...\n",
      "Processing at 80.0000000 percent ...\n",
      "Processing at 90.0000000 percent ...\n",
      "Processing at 100.0000000 percent ...\n",
      "Total real-time runtime: 10.1942875 sec.\n",
      "Average real-time kernel runtime:  0.0137104 sec.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "a = numpy.array([fX[0], fY[0]])\n",
    "b = numpy.array([fX[-1], fY[-1]])\n",
    "t_0_N = numpy.array([ftimes[0], ftimes[-1]])\n",
    "T = t_0_N[1]-t_0_N[0]\n",
    "dt = 12.0 * 60.0 * 60.0\n",
    "sim_steps = int(math.floor(T/dt))\n",
    "\n",
    "for i in range(0, 5000):\n",
    "    pt = (b - a) * numpy.random.random_sample(2)  + a\n",
    "    sim.add_particle(pt[0], pt[1])\n",
    "\n",
    "rt_times_kernel = []\n",
    "\n",
    "print(\"==== running JUST the simulation ====\")\n",
    "stime_rt_sim = rt_timer()\n",
    "prev_int_proc = -1\n",
    "cur_int_proc = 0\n",
    "while sim.sim_time < sim.sim_end_time:\n",
    "    stime_rt_kernel = rt_timer()\n",
    "    sim.advect_once(dt)\n",
    "    etime_rt_kernel = rt_timer()\n",
    "    rt_times_kernel.append(etime_rt_kernel-stime_rt_kernel)\n",
    "    proc_done = (sim.sim_time / sim.sim_end_time)*100\n",
    "    cur_int_proc = int(math.floor(proc_done/10))\n",
    "    if prev_int_proc != cur_int_proc:\n",
    "        print(\"Processing at {:10.7f} percent ...\".format(proc_done))\n",
    "    prev_int_proc = cur_int_proc\n",
    "\n",
    "etime_rt_sim = rt_timer()\n",
    "print(\"Total real-time runtime: {:10.7f} sec.\".format(etime_rt_sim-stime_rt_sim))\n",
    "avg = numpy.array(rt_times_kernel).mean()\n",
    "print(\"Average real-time kernel runtime: {:10.7f} sec.\".format(avg))\n",
    "del sim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This simulation alone tells us very little about the performance. As we need a comparison figure, we proceed as we\n",
    "did before with the 100ms-time measurement: we run the simulation and measure the *processing runtime* during the \n",
    "execution of many other, competing processes. This will allow us to validate if we see similar timing distortions with\n",
    "the physical simulation as we did before with the abstract simulation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "==== running the simulation with competing procs ====\n",
      "Processing at  0.1351351 percent ...\n",
      "Processing at 10.0000000 percent ...\n",
      "Processing at 20.0000000 percent ...\n",
      "Processing at 30.0000000 percent ...\n",
      "Processing at 40.0000000 percent ...\n",
      "Processing at 50.0000000 percent ...\n",
      "Processing at 60.0000000 percent ...\n",
      "Processing at 70.0000000 percent ...\n",
      "Processing at 80.0000000 percent ...\n",
      "Processing at 90.0000000 percent ...\n",
      "Processing at 100.0000000 percent ...\n",
      "Total real-time runtime: 110.0267024 sec.\n",
      "Average real-time kernel runtime:  0.1476274 sec.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sim_interference_delay = 0.001\n",
    "def sim_interference(sync_bit):\n",
    "    is_done = False\n",
    "    \n",
    "    rng = default_rng()\n",
    "    matrix = rng.standard_normal(size=(64, 64))\n",
    "    kernel = rng.standard_normal(size=(3, 3)) \n",
    "    while not is_done:\n",
    "        # temp = numpy.convolve(matrix, kernel, mode='same')\n",
    "        temp = signal.convolve2d(matrix, kernel, boundary='symm', mode='same')\n",
    "        matrix = temp\n",
    "        sleep(sim_interference_delay)\n",
    "        is_done = sync_bit.is_set()\n",
    "\n",
    "write_anim = False\n",
    "sim = None\n",
    "if write_anim:\n",
    "    sim = Simulation(fX, fY, ftimes, fU, fV, num_visual_traces=25)\n",
    "else:\n",
    "    sim = Simulation(fX, fY, ftimes, fU, fV)\n",
    "\n",
    "for i in range(0, 5000):\n",
    "    pt = (b - a) * numpy.random.random_sample(2)  + a\n",
    "    sim.add_particle(pt[0], pt[1])\n",
    "\n",
    "rt_times_kernel.clear()\n",
    "sync_bit.clear()\n",
    "concurrent_processes = [Process(target=sim_interference, args=(sync_bit,)) for i in range(0, 100)]\n",
    "for proc in concurrent_processes:\n",
    "    proc.start()\n",
    "\n",
    "print(\"==== running the simulation with competing procs ====\")\n",
    "stime_rt_sim = rt_timer()\n",
    "prev_int_proc = -1\n",
    "cur_int_proc = 0\n",
    "while sim.sim_time < sim.sim_end_time:\n",
    "    stime_rt_kernel = rt_timer()\n",
    "    sim.advect_once(dt)\n",
    "    etime_rt_kernel = rt_timer()\n",
    "    rt_times_kernel.append(etime_rt_kernel-stime_rt_kernel)\n",
    "    proc_done = (sim.sim_time / sim.sim_end_time)*100\n",
    "    cur_int_proc = int(math.floor(proc_done/10))\n",
    "    if prev_int_proc != cur_int_proc:\n",
    "        print(\"Processing at {:10.7f} percent ...\".format(proc_done))\n",
    "    prev_int_proc = cur_int_proc\n",
    "\n",
    "sync_bit.set()\n",
    "etime_rt_sim = rt_timer()\n",
    "print(\"Total real-time runtime: {:10.7f} sec.\".format(etime_rt_sim-stime_rt_sim))\n",
    "avg = numpy.array(rt_times_kernel).mean()\n",
    "print(\"Average real-time kernel runtime: {:10.7f} sec.\".format(avg))\n",
    "\n",
    "\n",
    "for proc in concurrent_processes:\n",
    "    proc.join()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's first visualise the simulation for visual verification before discussing the timing results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, writers\n",
    "from DecayLine import DecayLine\n",
    "\n",
    "\n",
    "if write_anim:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    cs = ax.pcolormesh(fX, fY, fU[0], shading='gouraud', zorder=1)\n",
    "    cs.cmap.set_over('k')\n",
    "    cs.cmap.set_under('w')\n",
    "    ax.set_title(\"Simulation t = %10.4f s\"% (0))\n",
    "    lines = []\n",
    "    for i in range(0, 25):\n",
    "        lines.append(DecayLine(14, 8, [1.0, 0.625, 0.], zorder=2+i))\n",
    "    \n",
    "    for i in range(0, 25):\n",
    "        lpt = sim[i].pt\n",
    "        lines[i].add_point(lpt[0], lpt[1])\n",
    "    \n",
    "    for l in lines:\n",
    "        ax.add_collection(l.get_LineCollection())\n",
    "    plt.show()\n",
    "\n",
    "    def init():\n",
    "        cs.set_array(fU[0].ravel())\n",
    "        \n",
    "        results = [cs, ]\n",
    "        for l in lines:\n",
    "            results.append(l.get_LineCollection())\n",
    "    \n",
    "        ax.set_title(\"Simulation t = %10.4f s\"% (0.))\n",
    "        return results\n",
    "    \n",
    "    def update_flow_only(frames, *args):\n",
    "        if (frames % 100) == 0:\n",
    "            print(\"Plotting frame {} ...\".format(frames))\n",
    "        dt = args[0]\n",
    "        tx = float(frames)*dt\n",
    "        tx = math.fmod(tx, ftimes[-1])\n",
    "        ti0 = sim.time_index_value(tx)\n",
    "        tt = sim.time_partion_value(tx)\n",
    "        ti1 = 0\n",
    "        if ti0 < (len(ftimes)-1):\n",
    "            ti1 = ti0+1\n",
    "        else:\n",
    "            ti1 = 0\n",
    "        fu_show = tt*fU[ti0] + (1.0-tt)*fU[ti1]\n",
    "        cs.set_array(fu_show.ravel())\n",
    "        \n",
    "        if frames>0:\n",
    "            for pindex in range(0, 25):\n",
    "                pt = sim[pindex].point(frames)\n",
    "                lines[pindex].add_point(pt[0], pt[1])\n",
    "        \n",
    "        results = [cs, ]\n",
    "        for l in lines:\n",
    "            results.append(l.get_LineCollection())\n",
    "    \n",
    "        ax.set_title(\"Simulation t = %10.4f s\"% (tx))\n",
    "        return results\n",
    "    \n",
    "    #Writer = writers['ffmpeg']\n",
    "    #ani_writer = Writer(fps=25, bitrate=24000)\n",
    "    Writer = writers['imagemagick_file']\n",
    "    ani_writer = Writer()\n",
    "    \n",
    "    #plt.show()\n",
    "    #ani = FuncAnimation(fig, update_flow_only, init_func=init, frames=sim_steps, interval=25, fargs=[dt,], blit=True)\n",
    "    #ani.save(\"flow_w_particles.mp4\", writer=ani_writer)\n",
    "\n",
    "    ani = FuncAnimation(fig, update_flow_only, init_func=init, frames=sim_steps, fargs=[dt,], blit=True)\n",
    "    ani.save(\"video_imgs/flow_w_particles.png\", writer=ani_writer, dpi=150)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We observe a similar (if not even more drastic) timing deviation as before: When competing, simulation-unrelated \n",
    "background processes are running, the measured *processing runtime* of our simulation increases _without having made any \n",
    "modification to the simulation code itself*.\n",
    "\n",
    "Million-dollar question: Does the simulation __itself__ really take many times longer ? After all, we haven't done anything to the simulation that could cause it to run longer, or have we ?\n",
    "\n",
    "Billion-dollar question: Is it possible that we are measuring **time** itself incorrectly ?\n",
    "\n",
    "Answering these questions is important to (a) *measure* the performance of a program, process or simulation, \n",
    "to (b) *locate* actual performance bottlenecks within the simulation-in-question and \n",
    "to (c) *improve* the performance, efficiency and scalability of a simulation by addressing the _actual_ performance bottlenecks.\n",
    "\n",
    "It's also important if your actual goal is to  get academic recognition (i.t.o. published papers) from your peers in the computer-scientific domain that actually\n",
    "cares about performance and efficiency - namely *High-Performance Computing (HPC)*. A paper that doesn't know which *time* it measures\n",
    "or that measures the *incorrect time*, is not getting published or cited.\n",
    "\n",
    "So, where does this discrepancy in time measurements actually originate ?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "del sim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "=> **Lecture slides**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Take-away messages\n",
    "- real-world time /neq processing time\n",
    "- processing time /neq compute time\n",
    "\n",
    "processing time = turnaround time = the time that *your process* spends doing *something* between 2 time measurements\n",
    "\n",
    "processing time consists of:\n",
    "- (external) I/O waiting time -> time spend by your process to access files, databases or network streams\n",
    "- (internal) I/O waiting time = memory I/O -> time spend copying *data* between different locations in *memory* -> quite a large chunk of time spend in Python\n",
    "- draw-out waiting time -> plotting time\n",
    "- compute time = *service time* -> the actual time spent in calculating stuff"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, before going into detail what those partial times are telling you, let's check where we are.\n",
    "\n",
    "We observed that **(a)** measuring a specific time frame (e.g. 100 ms) isn't done accurately by measuring the global time passed in the real-world during the measurement,\n",
    "and that **(b)** the measured time it takes to perform a simulation varies with respect to other competing processes active in a given computing system (i.e. *a machine*).\n",
    "\n",
    "Our major questions where:\n",
    "- Why do those time measurements differ ? \n",
    "\n",
    "*Theory*: we measure time incorrectly, or: we measure the 'wrong' time.\n",
    "- What is the culprit ?\n",
    "\n",
    "*Answer*: process interference from concurrently running processes, that result in the fact that the procedure or process we want to measure does not run at each and every moment - it needs to share its processing time with those other cocurrent process, which is managed by the *process scheduler* of the *operating system*, and thus: out of our control.\n",
    "- Do we need to care about the measurement differences ?\n",
    "\n",
    "*Answer*: We need to care if *(a)* our calculation depends on measuring the time passed between two instances or *(b)* if we want to measure how long it takes to execute a simulation, thus making _educated_ statements about computational bottlenecks and prioritise performance improvements sensefully. \n",
    "- *How do we make sure that we measure time the way we intend it to do ?* -> to come now ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computers, Python, Clocks and Time - Different clocks for different demands and situations\n",
    "\n",
    "The computer, the operating system and Python (as the programmable interface for practitioners) provide different clocks for addressing the different situations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Real-world clocks\n",
    "\n",
    "In order two measure the time passed between two events in the real world, on a global level as seen from a computer-perspective, Python provides ous with two packages we already know."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from time import time as rt_timer\n",
    "from datetime import datetime as rt_clock\n",
    "\n",
    "def time_globally():\n",
    "    stime_rt_global = rt_timer()\n",
    "    sclock_rt_global = rt_clock.now()\n",
    "    # ----------------------------------------------------- #\n",
    "    # -- perform something here - or just: let time pass -- #\n",
    "    # ----------------------------------------------------- #\n",
    "    etime_rt_global = rt_timer()\n",
    "    eclock_rt_global = rt_clock.now()\n",
    "    # -- times passed in real-world clocks.     -- #\n",
    "    # -- It will be equal to you measuring time -- #\n",
    "    # -- on a manual clock simultaneously.      -- #\n",
    "    delta_t_time_func = etime_rt_global-stime_rt_global\n",
    "    delta_t_clock_func = eclock_rt_global-sclock_rt_global"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While taking this global, real-world equivalent clock to measure time, it is incorrect in 99.99999 percent of the cases that involve computerised procedures."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Global computational clocks with a high resolution (~ 1-0.1 ns)\n",
    "\n",
    "There exists a more high-resolution global clock that is not bound to the low-resolution system clock of the operating system, but on the clocks of the CPU. Python gives access to that clock via:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from time import perf_counter as rt_timer_hr\n",
    "\n",
    "def compute_time_ptimer_hr():\n",
    "    stime_ptimer_hr = compute_ptimer_hr()\n",
    "    # --------------------------- #\n",
    "    # -- perform a calculation -- #\n",
    "    # --------------------------- #\n",
    "    etime_ptimer_hr = compute_ptimer_hr()\n",
    "    delta_t_ptimer_hr_func = etime_ptimer_hr-stime_ptimer_hr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process-owned computational clock with a low resolution (~1 sec. to 1/10th sec.)\n",
    "\n",
    "If we are actually interested in finding bottlenecks in a computation within a process, a low-resolution clock (based on the system clock of the operating system) that can avoid numeric overflows in the time measurement for long time spans can be accessed. The natural drawback\n",
    "for expressing long time spans and thus high-integer numbers is that the clocks are limited in their resolution. Python provides us specifically with the following packages:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "2.274000053148484e-06"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "# from timeit import timeit\n",
    "from timeit import timeit\n",
    "\n",
    "def compute_time_via_timeit():\n",
    "    # --------------------------- #\n",
    "    # -- perform a calculation -- #\n",
    "    # --------------------------- #\n",
    "    i = 0\n",
    "    return True\n",
    "\n",
    "timeit(\"compute_time_via_timeit()\", setup=\"from __main__ import compute_time_via_timeit\", number=10)\n",
    "\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process-owned computational clock with a high-resolution (~ 1-0.1 ns)\n",
    "\n",
    "If we are actually interested in finding bottlenecks in a computation within a process that account \n",
    "for the scheduling- and process concurrency error _on a single machine_, then the operating system and Python provide us with\n",
    "process-bound high resolution clocks. Due to the supreme processing speed of any modern computer,\n",
    "individual functions are executed within just a few 100 (<500) clock ticks of the CPU - example: our per-particle kernel. \n",
    "To put this number in perspective:\n",
    "\n",
    "A modern computer has an adaptive clock speed. If I measure this on my local machine (-> Ubuntu laptop), the clock speed ranges between\n",
    "\n",
    "400 MHz (idle mode) - 4600 MHz (when doing calculations)\n",
    "\n",
    "At that speed, each clock tick of the CPU takes 217 ns. Hence, calculating a particle kernel for a single particle requires at max. ~108 ps. This means three things:\n",
    "- (i)   a low-resolution clock is useless for measuring processing speed and performance.\n",
    "- (ii)  a resolution below 1 ns is none-sense - meaning also that we cannot measure any phenomenon with *common computers* that takes less than 1 ns\n",
    "- (iii) such a high-resolution clock is based on counting CPU clocks themselves. This means that we do get a very high resolution, but it also means that we can only measure times between 10^-12 sec. to 10^7 sec. with this clock. Thus: we cannot measure long-running procedures with this clock.\n",
    "\n",
    "Now, how does Python allow us to use this clock ?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from time import process_time as compute_ptimer_hr\n",
    "\n",
    "def compute_time_ptimer_lr():\n",
    "    stime_ptimer_lr = compute_ptimer_hr()\n",
    "    # --------------------------- #\n",
    "    # -- perform a calculation -- #\n",
    "    # --------------------------- #\n",
    "    etime_ptimer_lr = compute_ptimer_hr()\n",
    "    delta_t_ptimer_lr_func = etime_ptimer_lr-stime_ptimer_lr\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bringing it all together - A - Measure 100 ms\n",
    "\n",
    "Now, lets measure the 100ms-gap with the different timer means during process-concurrency interference. First, we define the timing functions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def measure_time_globally(sync_bit=None, print_each=False):\n",
    "    current_time = rt_timer()\n",
    "    stime_rt_global = rt_timer()\n",
    "    etime_rt_global = rt_timer()\n",
    "    rt_global_stime = current_time\n",
    "    rt_time_deltas = []\n",
    "    \n",
    "    printed = False\n",
    "    while (current_time-rt_global_stime) < 1.0:\n",
    "        current_time = rt_timer()\n",
    "        if (current_time-stime_rt_global) >= 0.1:\n",
    "            etime_rt_global = rt_timer()\n",
    "            dt_rt_timer_global = etime_rt_global-stime_rt_global\n",
    "            if print_each or not printed:\n",
    "                print(\"--------------------------------------------------------------\")\n",
    "                print(\"'dt' via real-world global timer: {:10.7f}\".format(dt_rt_timer_global))\n",
    "            rt_time_deltas.append( math.fabs(dt_rt_timer_global-0.1) )\n",
    "            if print_each or not printed:\n",
    "                print(\"abs_delta(timer, definitive dt=100ms): {:10.7f}\".format(rt_time_deltas[-1]))\n",
    "                print(\"--------------------------------------------------------------\")\n",
    "            stime_rt_global = etime_rt_global\n",
    "            printed = True\n",
    "        sleep(0.02)\n",
    "    \n",
    "    time_deltas = numpy.array(rt_time_deltas)\n",
    "    if sync_bit is not None:\n",
    "        sync_bit.set()\n",
    "    return time_deltas\n",
    "\n",
    "def measure_global_time_hr(sync_bit=None, print_each=False):\n",
    "    current_time = rt_timer_hr()\n",
    "    stime_rt_global = rt_timer_hr()\n",
    "    etime_rt_global = rt_timer_hr()\n",
    "    rt_global_stime = current_time\n",
    "    rt_time_deltas = []\n",
    "    \n",
    "    printed = False\n",
    "    while (current_time-rt_global_stime) < 1.0:\n",
    "        current_time = rt_timer_hr()\n",
    "        if (current_time-stime_rt_global) >= 0.1:\n",
    "            etime_rt_global = rt_timer_hr()\n",
    "            dt_rt_timer_global = etime_rt_global-stime_rt_global\n",
    "            if print_each or not printed:\n",
    "                print(\"--------------------------------------------------------------\")\n",
    "                print(\"'dt' via low-resolution process timer: {:10.7f}\".format(dt_rt_timer_global))\n",
    "            rt_time_deltas.append( math.fabs(dt_rt_timer_global-0.1) )\n",
    "            if print_each or not printed:\n",
    "                print(\"abs_delta(timer, definitive dt=100ms): {:10.7f}\".format(rt_time_deltas[-1]))\n",
    "                print(\"--------------------------------------------------------------\")\n",
    "            stime_rt_global = etime_rt_global\n",
    "            printed = True\n",
    "        sleep(0.02)\n",
    "    \n",
    "    time_deltas = numpy.array(rt_time_deltas)\n",
    "    if sync_bit is not None:\n",
    "        sync_bit.set()\n",
    "    return time_deltas\n",
    "\n",
    "def measure_compute_time_ptimer_hr(sync_bit=None, print_each=False):\n",
    "    current_time = compute_ptimer_hr()\n",
    "    stime_rt_global = compute_ptimer_hr()\n",
    "    etime_rt_global = compute_ptimer_hr()\n",
    "    rt_global_stime = current_time\n",
    "    rt_time_deltas = []\n",
    "    \n",
    "    printed = False\n",
    "    while (current_time-rt_global_stime) < 1.0:\n",
    "        current_time = compute_ptimer_hr()\n",
    "        if (current_time-stime_rt_global) >= 0.1:\n",
    "            etime_rt_global = compute_ptimer_hr()\n",
    "            dt_rt_timer_global = etime_rt_global-stime_rt_global\n",
    "            if print_each or not printed:\n",
    "                print(\"--------------------------------------------------------------\")\n",
    "                print(\"'dt' via high-resolution process timer: {:10.7f}\".format(dt_rt_timer_global))\n",
    "            rt_time_deltas.append( math.fabs(dt_rt_timer_global-0.1) )\n",
    "            if print_each or not printed:\n",
    "                print(\"abs_delta(timer, definitive dt=100ms): {:10.7f}\".format(rt_time_deltas[-1]))\n",
    "                print(\"--------------------------------------------------------------\")\n",
    "            stime_rt_global = etime_rt_global\n",
    "            printed = True\n",
    "        sleep(0.02)\n",
    "    \n",
    "    time_deltas = numpy.array(rt_time_deltas)\n",
    "    if sync_bit is not None:\n",
    "        sync_bit.set()\n",
    "    return time_deltas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we start the simulation.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------\n",
      "'dt' via real-world global timer:  0.1003423\n",
      "abs_delta(timer, definitive dt=100ms):  0.0003423\n",
      "--------------------------------------------------------------\n",
      "Measuring 1.0s in 0.1s steps in real-world time via the global timer took 1.0212059020996094 sec.\n",
      "--------------------------------------------------------------\n",
      "'dt' via low-resolution process timer:  0.1003890\n",
      "abs_delta(timer, definitive dt=100ms):  0.0003890\n",
      "--------------------------------------------------------------\n",
      "Measuring 1.0s in 0.1s steps in real-world time via the high-resolution global timer took 1.0346643924713135 sec.\n",
      "--------------------------------------------------------------\n",
      "'dt' via high-resolution process timer:  0.1000025\n",
      "abs_delta(timer, definitive dt=100ms):  0.0000025\n",
      "--------------------------------------------------------------\n",
      "Measuring 1.0s in 0.1s steps in real-world time via the high-resolution process timer took 411.07519721984863 sec.\n",
      "Statistical comparison:\n",
      "\ttime-deltas - global timer [s]\n",
      "\t\tmin:  0.0003423\n",
      "\t\tmax:  0.0141684\n",
      "\t\tavg:  0.0022934\n",
      "\t\tstd_dev:  0.0042272\n",
      "\ttime-deltas - high-resolution global timer [s]\n",
      "\t\tmin:  0.0002772\n",
      "\t\tmax:  0.0068280\n",
      "\t\tavg:  0.0014404\n",
      "\t\tstd_dev:  0.0021413\n",
      "\ttime-deltas - high-resolution process timer [s]\n",
      "\t\tmin:  0.0000025\n",
      "\t\tmax:  0.0000505\n",
      "\t\tavg:  0.0000328\n",
      "\t\tstd_dev:  0.0000150\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from multiprocessing import Process, Event\n",
    "nsync = Event()\n",
    "concurrent_processes = [Process(target=external_work, args=(nsync,)) for i in range(0, 200)]\n",
    "for proc in concurrent_processes:\n",
    "    proc.start()\n",
    "\n",
    "rt_start = rt_timer()\n",
    "global_time_dts = measure_time_globally()\n",
    "rt_end = rt_timer()\n",
    "print(\"Measuring 1.0s in 0.1s steps in real-world time via the global timer took {} sec.\".format(rt_end-rt_start))\n",
    "rt_start = rt_timer()\n",
    "global_hr_time_dts = measure_global_time_hr()\n",
    "rt_end = rt_timer()\n",
    "print(\"Measuring 1.0s in 0.1s steps in real-world time via the high-resolution global timer took {} sec.\".format(rt_end-rt_start))\n",
    "rt_start = rt_timer()\n",
    "ptimer_hr_time_dts = measure_compute_time_ptimer_hr()\n",
    "rt_end = rt_timer()\n",
    "print(\"Measuring 1.0s in 0.1s steps in real-world time via the high-resolution process timer took {} sec.\".format(rt_end-rt_start))\n",
    "nsync.set()\n",
    "\n",
    "for proc in concurrent_processes:\n",
    "    proc.join()\n",
    "\n",
    "print(\"Statistical comparison:\")\n",
    "print(\"\\ttime-deltas - global timer [s]\")\n",
    "print(\"\\t\\tmin: {:10.7f}\".format(global_time_dts.min()))\n",
    "print(\"\\t\\tmax: {:10.7f}\".format(global_time_dts.max()))\n",
    "print(\"\\t\\tavg: {:10.7f}\".format(global_time_dts.mean()))\n",
    "print(\"\\t\\tstd_dev: {:10.7f}\".format(global_time_dts.std()))\n",
    "print(\"\\ttime-deltas - high-resolution global timer [s]\")\n",
    "print(\"\\t\\tmin: {:10.7f}\".format(global_hr_time_dts.min()))\n",
    "print(\"\\t\\tmax: {:10.7f}\".format(global_hr_time_dts.max()))\n",
    "print(\"\\t\\tavg: {:10.7f}\".format(global_hr_time_dts.mean()))\n",
    "print(\"\\t\\tstd_dev: {:10.7f}\".format(global_hr_time_dts.std()))\n",
    "print(\"\\ttime-deltas - high-resolution process timer [s]\")\n",
    "print(\"\\t\\tmin: {:10.7f}\".format(ptimer_hr_time_dts.min()))\n",
    "print(\"\\t\\tmax: {:10.7f}\".format(ptimer_hr_time_dts.max()))\n",
    "print(\"\\t\\tavg: {:10.7f}\".format(ptimer_hr_time_dts.mean()))\n",
    "print(\"\\t\\tstd_dev: {:10.7f}\".format(ptimer_hr_time_dts.std()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bringing it all together - B - Measure the Simulation Time\n",
    "\n",
    "In the second stage, we're measuring the actual particle simulation time with the different timer means during process-concurrency interference. Our new simulation core looks then as such:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "==== running the simulation with competing procs ====\n",
      "Processing at  0.1351351 percent ...\n",
      "Processing at 10.0000000 percent ...\n",
      "Processing at 20.0000000 percent ...\n",
      "Processing at 30.0000000 percent ...\n",
      "Processing at 40.0000000 percent ...\n",
      "Processing at 50.0000000 percent ...\n",
      "Processing at 60.0000000 percent ...\n",
      "Processing at 70.0000000 percent ...\n",
      "Processing at 80.0000000 percent ...\n",
      "Processing at 90.0000000 percent ...\n",
      "Processing at 100.0000000 percent ...\n",
      "Total real-time runtime (low-res timer): 793.3096852 sec.\n",
      "Total real-time runtime (high-res timer): 793.3096816 sec.\n",
      "Total processing time (high-res timer): 63.3586130 sec.\n",
      "Average real-time kernel runtime (low-res timer):  1.0709121 sec.\n",
      "Average real-time kernel runtime (high-res timer):  1.0709135 sec.\n",
      "Average processing kernel time (high-res timer):  0.0855392 sec.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sim = Simulation(fX, fY, ftimes, fU, fV)\n",
    "for i in range(0, 5000):\n",
    "    pt = (b - a) * numpy.random.random_sample(2)  + a\n",
    "    sim.add_particle(pt[0], pt[1])\n",
    "\n",
    "nsync.clear()\n",
    "concurrent_processes = [Process(target=sim_interference, args=(nsync,)) for i in range(0, 100)]\n",
    "for proc in concurrent_processes:\n",
    "    proc.start()\n",
    "\n",
    "rt_global_lr_times_kernel = []\n",
    "rt_global_hr_times_kernel = []\n",
    "ptimer_hr_times_kernel = []\n",
    "\n",
    "print(\"==== running the simulation with competing procs ====\")\n",
    "stime_rt_lr_sim = rt_timer()\n",
    "stime_rt_hr_sim = rt_timer_hr()\n",
    "stime_ptimer_hr_sim = compute_ptimer_hr()\n",
    "prev_int_proc = -1\n",
    "cur_int_proc = 0\n",
    "while sim.sim_time < sim.sim_end_time:\n",
    "    stime_rt_global_lr = rt_timer()\n",
    "    stime_rt_global_hr = rt_timer_hr()\n",
    "    stime_ptimer_hr = compute_ptimer_hr()\n",
    "    sim.advect_once(dt)\n",
    "    etime_rt_global_lr = rt_timer()\n",
    "    etime_rt_global_hr = rt_timer_hr()\n",
    "    etime_ptimer_hr = compute_ptimer_hr()\n",
    "    rt_global_lr_times_kernel.append(etime_rt_global_lr-stime_rt_global_lr)\n",
    "    rt_global_hr_times_kernel.append(etime_rt_global_hr-stime_rt_global_hr)\n",
    "    ptimer_hr_times_kernel.append(etime_ptimer_hr-stime_ptimer_hr)\n",
    "    proc_done = (sim.sim_time / sim.sim_end_time)*100\n",
    "    cur_int_proc = int(math.floor(proc_done/10))\n",
    "    if prev_int_proc != cur_int_proc:\n",
    "        print(\"Processing at {:10.7f} percent ...\".format(proc_done))\n",
    "    prev_int_proc = cur_int_proc\n",
    "\n",
    "nsync.set()\n",
    "etime_rt_lr_sim = rt_timer()\n",
    "etime_rt_hr_sim = rt_timer_hr()\n",
    "etime_ptimer_hr_sim = compute_ptimer_hr()\n",
    "print(\"Total real-time runtime (low-res timer): {:10.7f} sec.\".format(etime_rt_lr_sim-stime_rt_lr_sim))\n",
    "print(\"Total real-time runtime (high-res timer): {:10.7f} sec.\".format(etime_rt_hr_sim-stime_rt_hr_sim))\n",
    "print(\"Total processing time (high-res timer): {:10.7f} sec.\".format(etime_ptimer_hr_sim-stime_ptimer_hr_sim))\n",
    "avg_rt_lr = numpy.array(rt_global_lr_times_kernel).mean()\n",
    "avg_rt_hr = numpy.array(rt_global_hr_times_kernel).mean()\n",
    "avg_ptimer_hr = numpy.array(ptimer_hr_times_kernel).mean()\n",
    "print(\"Average real-time kernel runtime (low-res timer): {:10.7f} sec.\".format(avg_rt_lr))\n",
    "print(\"Average real-time kernel runtime (high-res timer): {:10.7f} sec.\".format(avg_rt_hr))\n",
    "print(\"Average processing kernel time (high-res timer): {:10.7f} sec.\".format(avg_ptimer_hr))\n",
    "\n",
    "\n",
    "for proc in concurrent_processes:\n",
    "    proc.join()\n",
    "    \n",
    "del sim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bringing it all together - C - I/O time vs. Compute time\n",
    "\n",
    "In this last case, we want to now get a measure of the overall I/O time (for files and memory) and the bare compute time. This will, in the end, reliable tell us something about the simulation behaviour and where the bottlenecks are."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/ckehl/.local/lib/python3.6/site-packages/scipy/io/netcdf.py:314: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\n",
      "  ), category=RuntimeWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "del fX\n",
    "del fY\n",
    "del ftimes\n",
    "del fU\n",
    "del fV\n",
    "# ==== Load flow-field data - measure the time ==== #\n",
    "s_io_file_time = compute_ptimer_hr()\n",
    "f = netcdf.netcdf_file('perlin.nc', 'r')\n",
    "ftimes = f.variables['time'].data\n",
    "fX = f.variables['lon'].data\n",
    "fY = f.variables['lat'].data\n",
    "fU = f.variables['u'].data\n",
    "fV = f.variables['v'].data\n",
    "f.close()\n",
    "e_io_file_time = compute_ptimer_hr()\n",
    "io_file_time = e_io_file_time-s_io_file_time\n",
    "\n",
    "# griddims = (ftimes, fY, fX)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "simulation field data obtained prepared "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class Simulation_Benchmark(Simulation):\n",
    "    def __init__(self, fx, fy, ft, fu, fv, num_visual_traces=0):\n",
    "        super(Simulation_Benchmark, self).__init__(fx, fy, ft, fu, fv, num_visual_traces)\n",
    "        self._io_mem_time = 0\n",
    "        self._compute_time = 0\n",
    "        \n",
    "    def __del__(self):\n",
    "        super(Simulation_Benchmark, self).__del__()\n",
    "        \n",
    "    def add_particle(self, x, y):\n",
    "        stime = compute_ptimer_hr()\n",
    "        super(Simulation_Benchmark, self).add_particle(x,y)\n",
    "        etime = compute_ptimer_hr()\n",
    "        self._io_mem_time += (etime-stime)\n",
    "        \n",
    "    def advect_once(self, dt):\n",
    "        stime_calc = compute_ptimer_hr()\n",
    "        fdt = self._ft[1]-self._ft[0]\n",
    "        etime_calc = compute_ptimer_hr()\n",
    "        self._compute_time += (etime_calc-stime_calc)\n",
    "        x = []\n",
    "        y = []\n",
    "        t = []\n",
    "        stime_mem = compute_ptimer_hr()\n",
    "        for p in self._data:\n",
    "            x.append(p.pt[0])\n",
    "            y.append(p.pt[1])\n",
    "            t.append(p.pt[2])\n",
    "        pts = (numpy.array(t), numpy.array(y), numpy.array(x))\n",
    "        etime_mem = compute_ptimer_hr()\n",
    "        self._io_mem_time += (etime_mem-stime_mem)\n",
    "        stime_calc = compute_ptimer_hr()\n",
    "        us = interpn(self._gdims, self._fu, pts, method='linear', fill_value=.0)\n",
    "        vs = interpn(self._gdims, self._fv, pts, method='linear', fill_value=.0)\n",
    "        for i, p in enumerate(self._data):\n",
    "            #p.advect(self._fu, self._fv, self._gdims, dt, fdt)\n",
    "            p.advect_uv(us[i], vs[i], self._gdims, dt, fdt)\n",
    "        self._simtime += dt\n",
    "        etime_calc = compute_ptimer_hr()\n",
    "        self._compute_time += (etime_calc-stime_calc)\n",
    "    \n",
    "    @property\n",
    "    def io_mem_time(self):\n",
    "        return self._io_mem_time\n",
    "    \n",
    "    @property\n",
    "    def compute_time(self):\n",
    "        return self._compute_time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now run the simulation and measure the total and partial times"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "==== running the simulation with competing procs ====\n",
      "Processing at  0.1351351 percent ...\n",
      "Processing at 10.0000000 percent ...\n",
      "Processing at 20.0000000 percent ...\n",
      "Processing at 30.0000000 percent ...\n",
      "Processing at 40.0000000 percent ...\n",
      "Processing at 50.0000000 percent ...\n",
      "Processing at 60.0000000 percent ...\n",
      "Processing at 70.0000000 percent ...\n",
      "Processing at 80.0000000 percent ...\n",
      "Processing at 90.0000000 percent ...\n",
      "Processing at 100.0000000 percent ...\n",
      "Total processing time (high-res timer): 26.8487899 sec.\n",
      "Average processing kernel time (high-res timer):  0.0362425 sec.\n",
      "Compute percentage of simulation time: 83.8656838\n",
      "I/O percentage of simulation time: 13.7216521\n",
      "Ratio Compute time vs. I/O time:  6.1090806\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sim = Simulation_Benchmark(fX, fY, ftimes, fU, fV)\n",
    "for i in range(0, 5000):\n",
    "    pt = (b - a) * numpy.random.random_sample(2)  + a\n",
    "    sim.add_particle(pt[0], pt[1])\n",
    "\n",
    "ptimer_hr_times_kernel.clear()\n",
    "print(\"==== running the simulation with competing procs ====\")\n",
    "stime_ptimer_hr_sim = compute_ptimer_hr()\n",
    "prev_int_proc = -1\n",
    "cur_int_proc = 0\n",
    "while sim.sim_time < sim.sim_end_time:\n",
    "    stime_ptimer_hr = compute_ptimer_hr()\n",
    "    sim.advect_once(dt)\n",
    "    etime_ptimer_hr = compute_ptimer_hr()\n",
    "    ptimer_hr_times_kernel.append(etime_ptimer_hr-stime_ptimer_hr)\n",
    "    proc_done = (sim.sim_time / sim.sim_end_time)*100\n",
    "    cur_int_proc = int(math.floor(proc_done/10))\n",
    "    if prev_int_proc != cur_int_proc:\n",
    "        print(\"Processing at {:10.7f} percent ...\".format(proc_done))\n",
    "    prev_int_proc = cur_int_proc\n",
    "\n",
    "etime_ptimer_hr_sim = compute_ptimer_hr()\n",
    "sim_total_time = etime_ptimer_hr_sim-stime_ptimer_hr_sim\n",
    "print(\"Total processing time (high-res timer): {:10.7f} sec.\".format(sim_total_time))\n",
    "avg_ptimer_hr = numpy.array(ptimer_hr_times_kernel).mean()\n",
    "print(\"Average processing kernel time (high-res timer): {:10.7f} sec.\".format(avg_ptimer_hr))\n",
    "\n",
    "io_to_total_ratio = sim.io_mem_time / sim_total_time\n",
    "compute_to_total_ratio = sim.compute_time / sim_total_time\n",
    "compute_to_iototal = sim.compute_time / (sim.io_mem_time+io_file_time)\n",
    "\n",
    "print(\"Compute percentage of simulation time: {:10.7f}\".format(compute_to_total_ratio*100.0))\n",
    "print(\"I/O percentage of simulation time: {:10.7f}\".format(io_to_total_ratio*100.0))\n",
    "print(\"Ratio Compute time vs. I/O time: {:10.7f}\".format(compute_to_iototal))\n",
    "\n",
    "del sim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The final output number here is the key figure. Conclusion that are made about it:\n",
    "- *compute vs. io* >> 1.0: high computation density - lots of benefit from C-kernel computation or GPU Computing\n",
    "- *compute vs. io* >= 1.0: if I/O and CPU load are balanced, improved memory access procedures are the first-most advice to improve performance\n",
    "- 1.0 < *compute vs. io* < 0.1: main bottleneck culprit is memory - likely many *copy-array1-to-array2* operations, of which some may be unnecessary ? Improve memory utilisation by avoiding unnecessary copies\n",
    "- *compute vs. io* < 0.1 **or** *compute vs. io* << 0.1: main bottleneck (due to the orders of magnitude difference) has to be file-, database- or network communication. The code needs to optimize file access, only load required subset data and also buffer-write results into files. **Investing time in C-kernels, GPU Computing, Vectorisation or similar compute-enhancing techniques is a waste of time for simulations in this bracket!!**\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
