{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Short introduction to Julia\n",
    "\n",
    "- Oscar van der Heide\n",
    "- Phd at UMC Utrecht working on MRI\n",
    "\n",
    "- I'm **not** a computer scientist\n",
    "\n",
    "- The goal of this presentation will **not** be to convert you to Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Why C/C++/Fortran are fast\n",
    "\n",
    "- C/C++/Fortran are compiled languages\n",
    "\n",
    "- At \"compile time\", a compiler translates your human-readable code into machine instructions\n",
    "\n",
    "- At \"runtime\", computer executes the generated machine instructions\n",
    "\n",
    "- Not only does the compiler translate your code, it also performs many optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "### Pseudo C/C++/Fortran code\n",
    "function f(x)\n",
    "   \n",
    "    s = 0;\n",
    "    \n",
    "    for i = 1:length(x)\n",
    "        y = 2*x[i] + 3*x[i]^3\n",
    "        s += y\n",
    "    end\n",
    "    \n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The compiler will not compile such code. Why?\n",
    "\n",
    "- Functions like \"+\" and \"\\*\" can mean different things to a computer: adding 64 bit floats, 32 bit integers or booleans are all different\n",
    "\n",
    "- Each of the different implementations of \"+\" require different machine instructions to be executed\n",
    "\n",
    "- Since the types are not specified in the program, the compiler will throw an error: it does not know what machine instructions to generate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pseudo C/C++/Fortran code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "function f(\"Array of Float64's\" x)\n",
    "   \n",
    "    \"Float64\" s = 0;\n",
    "    \n",
    "    for \"Int64\" i = 1:length(x)\n",
    "        \"Float64\" y = 2*x[i] + 3*x[i]^3\n",
    "        s += y\n",
    "    end\n",
    "    \n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now all types are known at \"compile time\" because we provided type annotations\n",
    "\n",
    "- Compiler now knows exactly what machine instructions to generate for all the {+,-,*,^,...}'s\n",
    "\n",
    "- Compiler will also recognize that the same operation is performed many times in a loop and will perform optimizations (pipelining, SIMD vector instructions, function inlining)\n",
    "\n",
    "- The result will be *fast code*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### But development in C is not so fast ...\n",
    "\n",
    "- Because of the compilation required, you can't run code in an interactive session: you write your whole program first, compile it and then run it\n",
    "\n",
    "- Because of the required type annotations, you'll end up having to write a versions of `f` for `f_array_float64`, `f_array_float32`, `f_array_int64`, `f_array_int32`\n",
    "\n",
    "- But also maybe `f_array_complex_float64`, `f_array_complex_float32`, `f_array_complex_int64`, `f_array_complex_int32`\n",
    "\n",
    "\n",
    "- And also maybe something like `f_array_of_matrices_of_float64s`, because all the operations involved can be applied on matrices as well\n",
    "\n",
    "- In other words, your code will not be *generic*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Why Python/Matlab/R are slow\n",
    "\n",
    "- Python/Matlab/R are interpreted languages\n",
    "\n",
    "- No separate compile time and runtime\n",
    "\n",
    "- Instead, when you want to execute code, an \"interpreter\" parses and executes it *line-by-line*, *statement-by-statement*\n",
    "\n",
    "- This allows for interactive sessions\n",
    "\n",
    "- The interpreter will also take care of all the types for you so it easy to write (type) generic code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### But there's a price to pay in terms of performance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Pseudo Python/Matlab/R code\n",
    "\n",
    "function f(x)\n",
    "   \n",
    "    s = 0;\n",
    "    \n",
    "    for i = 1:length(x)\n",
    "        y = 2*x[i] + 3*x[i]^3 \n",
    "        s += y\n",
    "    end\n",
    "    \n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The interpreter basically sees this as a list of separate statements that, at runtime, it will go through one-by-one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s = 0;\n",
    "\n",
    "tmp1 = 2*x[1]\n",
    "tmp2 = x[1]^3\n",
    "tmp3 = 3*tmp2  \n",
    "tmp4 = tmp2 + tmp3\n",
    "s += tmp4\n",
    "...\n",
    "tmp101 = 2*x[100]\n",
    "tmp102 = x[100]^3\n",
    "tmp103 = 3*tmp102\n",
    "tmp104 = tmp102 + tmp103\n",
    "s += tmp104\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### At each statement the interpreter: \n",
    "\n",
    "1. checks the types of the input arguments to the function (e.g. +,-,*,^,...)\n",
    "\n",
    "2. retrieves a list of known implementations for the given function from memory   \n",
    "\n",
    "3. selects the appropriate method for the current types \n",
    "\n",
    "4. performs the computation\n",
    "\n",
    "\n",
    "The combination of the first three things is called \"dynamic dispatch\" or \"runtime type checking\". It is more time consuming than performing the actual computations (4).\n",
    "\n",
    "In addition, because the interpreter only has a \"local\" view of the code, it cannot optimize your code in a way that a compiler (with it's \"global\" view) can. \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Vectorization\n",
    "\n",
    "- This is why you are told to not write for loops in Python/Matlab/R\n",
    "- Instead, you are told to *vectorize* everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f(x) = sum(2*x + 3*x^3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When vectorizing code, under the hood calls are made to compiled library functions. \n",
    "- This way you can get C/C++/Fortran like performance from an interpreted language! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Why vectorized code may not be optimal\n",
    "\n",
    "- First of all, not all code can be properly vectorized ... \n",
    "\n",
    "- Secondly, and this is what we will focus on, vectorized code may be far from optimal\n",
    "\n",
    "- Let's look at an example (taken from https://julialang.org/blog/2017/01/moredots)\n",
    "\n",
    "- Suppose we have a function `f(y) = 3y^2 + 5y + 2` that evaluates a polynomial\n",
    "\n",
    "- And suppose we want to want to evaluate `f(2x^2 + 6x^3 - sqrt(x))` for a whole array `X`, storing the result in-place in `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Vectorized code\n",
    "\n",
    "N = 10^7\n",
    "X = rand(N,1)\n",
    "\n",
    "# Evaluate input to polynomial f\n",
    "Y = 2*X.^2 + 6*X.^3 - sqrt(X)\n",
    "\n",
    "# Evaluate polynomial f\n",
    "X = 3*Y.^2 + 5*Y + 2*ones(size(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There is no optimized C code for the operation as a whole, only for the individual components. Therefore the vectorized code will effectively do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Y = 2*X.^2 + 6*X.^3 - sqrt(X)\n",
    "# X = 3*Y.^2 + 5*Y + 2*ones(size(Y))\n",
    "\n",
    "# Evaluate input to polynomial f\n",
    "tmp1 = X.^2 \n",
    "tmp2 = 2*tmp1\n",
    "tmp3 = X.^3\n",
    "tmp4 = 6 * tmp3\n",
    "tmp5 = tmp2 + tmp4\n",
    "tmp6 = sqrt(X)\n",
    "tmp7 = tmp5 - tmp6\n",
    "# Evaluate polynomial f\n",
    "tmp8 = tmp7.^2\n",
    "tmp9 = 3*tmp8\n",
    "tmp10 = 5*tmp7\n",
    "tmp11 = tmp9 + tmp10\n",
    "tmp12 = tmp11 + 2*ones(size(X)) \n",
    "X = tmp12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Two problems with this vectorized code:\n",
    "\n",
    "1. Many unnecessary memory allocations. Will hurt performance especially if X is either very small or very large.\n",
    "\n",
    "2. In each line there is a new loop in which memory (RAM) is accessed and only a single operation (+,-, ^,sqrt,...) is performed. Memory access in general is expensive and it is better to retrieve each `X[i]` only once from memory and do as much scalar operations (`f(2*x^2 + 6*x^3 - sqrt(x)`) at once.\n",
    "\n",
    "\n",
    "You can solve these problems two problems with loops. But loops are slow in interpreted languages. So to get optimal performance (actual speedup compared to vectorized code will be shown later) you would have to write C/C++/Fortran code.\n",
    "\n",
    "Or ... use Julia :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. Julia\n",
    "\n",
    "- Julia is relatively new programming language: development started in 2009 at MIT, first release 2012, stable 1.0 release in 2018\n",
    "\n",
    "- It tries to bring you the best of both worlds: write type generic code like in an interpreted language with performance similar to compiled languages. \n",
    "\n",
    "- This is achieved through a combination of: \n",
    "\n",
    "    1. Just-in-time (JIT) compilation\n",
    "    2. Type inference\n",
    "    3. Multiple dispatch (not discussed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.1 Just-in-time (JIT) compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.015172 seconds (40.74 k allocations: 2.216 MiB)\n"
     ]
    }
   ],
   "source": [
    "function f(X)\n",
    "   \n",
    "    s = zero(eltype(X));\n",
    "    \n",
    "    for x ∈ X\n",
    "        s += 2x + 3x^3\n",
    "    end\n",
    "    \n",
    "    return s\n",
    "end\n",
    "\n",
    "X = rand(10^6)\n",
    "@time f(X); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Why all these allocations?! It's because the first time a function is called, it gets compiled\n",
    "\n",
    "Let's call the function again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.002332 seconds (5 allocations: 176 bytes)\n"
     ]
    }
   ],
   "source": [
    "@time f(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ahh that's better. Note that the 5 allocations are related to timing in global scope, there's a better way to benchmark functions as will be shown later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.2 Type inference\n",
    "\n",
    "- Notice that we did not specify the types of the variables in our function `f`. \n",
    "\n",
    "- How can the compiler compile if it doesn't know the types?\n",
    "\n",
    "- The compiler performs *type inference*: given the types of the input arguments to the function, it will try to deduce the types of all other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables\n",
      "  #self#\u001b[36m::Core.Compiler.Const(f, false)\u001b[39m\n",
      "  X\u001b[36m::Array{Float64,1}\u001b[39m\n",
      "  s\u001b[36m::Float64\u001b[39m\n",
      "  @_4\u001b[33m\u001b[1m::Union{Nothing, Tuple{Float64,Int64}}\u001b[22m\u001b[39m\n",
      "  x\u001b[36m::Float64\u001b[39m\n",
      "\n",
      "Body\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m %1  = Main.eltype(X)\u001b[36m::Core.Compiler.Const(Float64, false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (s = Main.zero(%1))\n",
      "\u001b[90m│  \u001b[39m %3  = X\u001b[36m::Array{Float64,1}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (@_4 = Base.iterate(%3))\n",
      "\u001b[90m│  \u001b[39m %5  = (@_4 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %6  = Base.not_int(%5)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #4 if not %6\n",
      "\u001b[90m2 ┄\u001b[39m %8  = @_4::Tuple{Float64,Int64}\u001b[36m::Tuple{Float64,Int64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (x = Core.getfield(%8, 1))\n",
      "\u001b[90m│  \u001b[39m %10 = Core.getfield(%8, 2)\u001b[36m::Int64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %11 = s\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %12 = (2 * x)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %13 = x\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %14 = Core.apply_type(Base.Val, 3)\u001b[36m::Core.Compiler.Const(Val{3}, false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %15 = (%14)()\u001b[36m::Core.Compiler.Const(Val{3}(), false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %16 = Base.literal_pow(Main.:^, %13, %15)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %17 = (3 * %16)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %18 = (%12 + %17)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (s = %11 + %18)\n",
      "\u001b[90m│  \u001b[39m       (@_4 = Base.iterate(%3, %10))\n",
      "\u001b[90m│  \u001b[39m %21 = (@_4 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %22 = Base.not_int(%21)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #4 if not %22\n",
      "\u001b[90m3 ─\u001b[39m       goto #2\n",
      "\u001b[90m4 ┄\u001b[39m       return s\n"
     ]
    }
   ],
   "source": [
    "@code_warntype f(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.2 Type inference\n",
    "\n",
    "- If the type inference is succesful, the compiler will be able to generate efficient machine instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: X not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: X not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[1]:1"
     ]
    }
   ],
   "source": [
    "@code_native f(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- So far we only called our function f with an array of `Float64`s as input\n",
    "\n",
    "- What if we call it with some other input, say, an array of `Int32`s?\n",
    "\n",
    "- The compiler sees that a function is called with *new* types of input variables and it will again start a compilation procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.016027 seconds (18.66 k allocations: 996.384 KiB)\n"
     ]
    }
   ],
   "source": [
    "X2 = rand(Int32, 10^6)\n",
    "@time f(X2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's call the function again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.003603 seconds (5 allocations: 176 bytes)\n"
     ]
    }
   ],
   "source": [
    "@time f(X2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we now look at the generated machine instructions, they will be different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.section\t__TEXT,__text,regular,pure_instructions\n",
      "; ┌ @ In[1]:5 within `f'\n",
      "; │┌ @ array.jl:704 within `iterate' @ array.jl:704\n",
      "; ││┌ @ In[1]:3 within `length'\n",
      "\tpushq\t%rax\n",
      "\tmovq\t8(%rsi), %r10\n",
      "; ││└\n",
      "\ttestq\t%r10, %r10\n",
      "\tjle\tL151\n",
      "; ││┌ @ array.jl:728 within `getindex'\n",
      "\tmovq\t(%rsi), %r9\n",
      "\tmovb\t$1, %dl\n",
      "\txorl\t%ecx, %ecx\n",
      "\tmovl\t$1, %r11d\n",
      "\tmovabsq\t$-4294967296, %r8       ## imm = 0xFFFFFFFF00000000\n",
      "\txorl\t%esi, %esi\n",
      "\tmovslq\t-4(%r9,%r11,4), %rax\n",
      "\tandb\t$3, %dl\n",
      "; │└└\n",
      "; │ @ In[1]:6 within `f'\n",
      "\tcmpb\t$1, %dl\n",
      "\tjne\tL89\n",
      "\tjmp\tL112\n",
      "\tnopw\t%cs:(%rax,%rax)\n",
      "; │ @ In[1]:5 within `f'\n",
      "L64:\n",
      "\tmovq\t%rsi, %rcx\n",
      "\tandq\t%r8, %rcx\n",
      "; │ @ In[1]:6 within `f'\n",
      "\taddq\t$1, %r11\n",
      "\tmovb\t$2, %dl\n",
      "; │ @ In[1]:5 within `f'\n",
      "; │┌ @ array.jl:704 within `iterate' @ array.jl:704\n",
      "; ││┌ @ array.jl:728 within `getindex'\n",
      "\tmovslq\t-4(%r9,%r11,4), %rax\n",
      "\tandb\t$3, %dl\n",
      "; │└└\n",
      "; │ @ In[1]:6 within `f'\n",
      "\tcmpb\t$1, %dl\n",
      "\tje\tL112\n",
      "L89:\n",
      "\tcmpb\t$2, %dl\n",
      "\tjne\tL163\n",
      "\tmovl\t%esi, %edx\n",
      "\torq\t%rcx, %rdx\n",
      "\tjmp\tL115\n",
      "\tnopw\t%cs:(%rax,%rax)\n",
      "; │┌ @ int.jl:872 within `+'\n",
      "; ││┌ @ int.jl:459 within `rem'\n",
      "L112:\n",
      "\tmovslq\t%esi, %rdx\n",
      "; │└└\n",
      "; │┌ @ intfuncs.jl:245 within `literal_pow'\n",
      "; ││┌ @ operators.jl:529 within `*' @ int.jl:54\n",
      "L115:\n",
      "\tmovl\t%eax, %ecx\n",
      "\timull\t%ecx, %ecx\n",
      "\timull\t%eax, %ecx\n",
      "; │└└\n",
      "; │┌ @ int.jl:872 within `*'\n",
      "; ││┌ @ int.jl:459 within `rem'\n",
      "\tmovslq\t%ecx, %rcx\n",
      "; ││└\n",
      "; ││ @ int.jl:54 within `*'\n",
      "\tleaq\t(%rcx,%rcx,2), %rcx\n",
      "; │└\n",
      "; │┌ @ int.jl:53 within `+'\n",
      "\tleaq\t(%rcx,%rax,2), %rsi\n",
      "\taddq\t%rdx, %rsi\n",
      "; │└\n",
      "; │┌ @ array.jl:704 within `iterate'\n",
      "; ││┌ @ int.jl:430 within `<' @ int.jl:423\n",
      "\tcmpq\t%r10, %r11\n",
      "; ││└\n",
      "\tjb\tL64\n",
      "; │└\n",
      "; │ @ In[1]:9 within `f'\n",
      "\tmovq\t%rsi, (%rdi)\n",
      "\tmovb\t$2, %dl\n",
      "\txorl\t%eax, %eax\n",
      "\tpopq\t%rcx\n",
      "\tretq\n",
      "L151:\n",
      "\tmovl\t$0, (%rdi)\n",
      "\tmovb\t$1, %dl\n",
      "\txorl\t%eax, %eax\n",
      "\tpopq\t%rcx\n",
      "\tretq\n",
      "; │ @ In[1]:6 within `f'\n",
      "L163:\n",
      "\tmovabsq\t$jl_throw, %rax\n",
      "\tmovabsq\t$jl_system_image_data, %rdi\n",
      "\tcallq\t*%rax\n",
      "\tnopl\t(%rax)\n",
      "; └\n"
     ]
    }
   ],
   "source": [
    "@code_native f(X2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Two *specializations* of the function `f` have now been compiled and stored in memory.\n",
    "\n",
    "But does our code really run as fast as, say, C code? Let's compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_c (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Julia code\n",
    "# using Pkg\n",
    "# Pkg.add(\"Libdl\")\n",
    "using Libdl\n",
    "C_code = \"\"\"\n",
    "#include <stddef.h>\n",
    "#include <math.h>\n",
    "double f_c(size_t n, double *X) \n",
    "{\n",
    "    double s = 0.0;\n",
    "    for (size_t i = 0; i < n; ++i) \n",
    "    {\n",
    "        double x = X[i];\n",
    "        double y = 2*x + 3*x*x*x;\n",
    "        s = s + y;\n",
    "    }\n",
    "    return s;\n",
    "}\n",
    "\"\"\"\n",
    "# compile to a shared library by piping C_code to gcc:\n",
    "# (only works if you have gcc installed)\n",
    "const Clib = tempname()\n",
    "open(`gcc -fPIC -O3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code)\n",
    "end\n",
    "\n",
    "function f_c(X::Array{Float64})\n",
    "    ccall((\"f_c\", Clib), Nothing, (Csize_t, Ptr{Float64}), length(X), X)\n",
    "    return X\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: Package BenchmarkTools not found in current path:\n- Run `import Pkg; Pkg.add(\"BenchmarkTools\")` to install the BenchmarkTools package.\n",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Package BenchmarkTools not found in current path:\n- Run `import Pkg; Pkg.add(\"BenchmarkTools\")` to install the BenchmarkTools package.\n",
      "",
      "Stacktrace:",
      " [1] require(::Module, ::Symbol) at ./loading.jl:876",
      " [2] top-level scope at In[11]:1"
     ]
    }
   ],
   "source": [
    "# properly time functions\n",
    "\n",
    "using BenchmarkTools\n",
    "@benchmark f_c($X);\n",
    "@benchmark f($X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So the Julia code is running just as fast as the C code for 64 bit floats. \n",
    "\n",
    "- But the Julia code is generic in the sense that it can be used for all \"things\" for which addition and (scalar) multiplication are defined. \n",
    "\n",
    "- That includes (however many bits) floats, integers, complex numbers, but also vectors and matrices and it also extends to more exotic user-defined types like dual numbers (for automatic differentiation) and numbers with uncertainties. \n",
    "\n",
    "- That's quite powerful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What if type inference fails?\n",
    "\n",
    "- Up to now we assumed the JIT compiler was able to deduce all types\n",
    "\n",
    "- If we write our code in a \"type unstable\" fashion, the compiler will not be able to deduce the types of all variables.\n",
    "\n",
    "- Instead of throwing an error, the compiler will generate code that performs type checking at runtime.\n",
    "\n",
    "- That is, it falls back to the dynamic dispatch behaviour that is the default in interpreted languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_unstable (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0.0\n",
    "\n",
    "function f_unstable(X)\n",
    "    \n",
    "    global s\n",
    "    for x ∈ X\n",
    "        s += 2x + 3x^3\n",
    "    end\n",
    "    \n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.033227 seconds (2.00 M allocations: 30.518 MiB, 3.18% gc time)\n",
      "  0.001107 seconds (5 allocations: 176 bytes)\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "f_unstable(X);\n",
    "\n",
    "# time\n",
    "@time f_unstable(X);\n",
    "\n",
    "# compare against type stable version\n",
    "@time f(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables\n",
      "  #self#\u001b[36m::Core.Compiler.Const(f_unstable, false)\u001b[39m\n",
      "  X\u001b[36m::Array{Float64,1}\u001b[39m\n",
      "  @_3\u001b[33m\u001b[1m::Union{Nothing, Tuple{Float64,Int64}}\u001b[22m\u001b[39m\n",
      "  x\u001b[36m::Float64\u001b[39m\n",
      "\n",
      "Body\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m       nothing\n",
      "\u001b[90m│  \u001b[39m %2  = X\u001b[36m::Array{Float64,1}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (@_3 = Base.iterate(%2))\n",
      "\u001b[90m│  \u001b[39m %4  = (@_3 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %5  = Base.not_int(%4)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #4 if not %5\n",
      "\u001b[90m2 ┄\u001b[39m %7  = @_3::Tuple{Float64,Int64}\u001b[36m::Tuple{Float64,Int64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (x = Core.getfield(%7, 1))\n",
      "\u001b[90m│  \u001b[39m %9  = Core.getfield(%7, 2)\u001b[36m::Int64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %10 = (2 * x)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %11 = x\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %12 = Core.apply_type(Base.Val, 3)\u001b[36m::Core.Compiler.Const(Val{3}, false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %13 = (%12)()\u001b[36m::Core.Compiler.Const(Val{3}(), false)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %14 = Base.literal_pow(Main.:^, %11, %13)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %15 = (3 * %14)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %16 = (%10 + %15)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %17 = (Main.s + %16)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (Main.s = %17)\n",
      "\u001b[90m│  \u001b[39m       (@_3 = Base.iterate(%2, %9))\n",
      "\u001b[90m│  \u001b[39m %20 = (@_3 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %21 = Base.not_int(%20)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #4 if not %21\n",
      "\u001b[90m3 ─\u001b[39m       goto #2\n",
      "\u001b[90m4 ┄\u001b[39m       return Main.s\n"
     ]
    }
   ],
   "source": [
    "@code_warntype f_unstable(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### JIT compilation + type inference + type stable code = fast code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. Loops vs vectorized code\n",
    "\n",
    "Let's go back to the earlier example of evaluating `f(2*x^2 + 6*x^3 - sqrt(x))` on an array X, with `f(y) = 3y^2 + 5y + 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: @benchmark not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: @benchmark not defined",
      ""
     ]
    }
   ],
   "source": [
    "function vectorized!(X)\n",
    "    Y = 2*X.^2+ 6*X.^3 - sqrt.(X)\n",
    "    X = 3*Y.^2 + 5*Y + 2*ones(size(Y))\n",
    "end\n",
    "\n",
    "\n",
    "f(y) = 3*y^2 + 5*y + 2\n",
    "y(x) = 2*x^2 + 6*x^3 - sqrt(x)\n",
    "\n",
    "function loop!(X)\n",
    "    for i in 1:length(X)\n",
    "        X[i] = f(y(X[i]))\n",
    "    end\n",
    "end\n",
    "\n",
    "# compile\n",
    "vectorized!(rand(10))\n",
    "loop!(rand(10))\n",
    "  \n",
    "# time\n",
    "X = rand(10^7)\n",
    "@benchmark vectorized!(X);\n",
    "@benchmark loop!(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite a significant difference in performance!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But vectorized code can sometimes improve readability of your code\n",
    "\n",
    "That's why there's \"dot syntax\" that allow you to write vectorized code while under the hood it gets transformed into loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.055088 seconds (4 allocations: 160 bytes)\n"
     ]
    }
   ],
   "source": [
    "function fused!(X)\n",
    "    @. X = f(y(X))\n",
    "end\n",
    "\n",
    "# compile \n",
    "fused!(rand(10))\n",
    "# time\n",
    "@time fused!(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6. Conclusion\n",
    "\n",
    "- Interpreted languages like Python/Matlab/R are slow because of type checking at runtime\n",
    "\n",
    "- For better performance in interpreted, you vectorize code so that compiled libraries can be called\n",
    "\n",
    "- But, optimized libraries only have code for basic operations. If you need to do more complicated operations, vectorized code performance suffers due to unnecessary memory allocations and accessing memory multiple times\n",
    "\n",
    "- In Julia for loops are fast (similar performance to C code) even though your code can be written in a very generic manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Additional things I like about Julia\n",
    "\n",
    "- \"Multiple dispatch\" type system <= perhaps the most interesting aspect of Julia\n",
    "\n",
    "\n",
    "- Built-in package and environment manager\n",
    "\n",
    "- Native support for both distributed and shared memory (see v1.3) computing\n",
    "\n",
    "- Many high quality packages for scientific computing (differential equations, optimization, machine learning, abstract math things) \n",
    "\n",
    "- Most of Julia and its packages are written in Julia itself: great learning resource\n",
    "\n",
    "- Unicode character support:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "∫φ²dt = Δt * φ²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Can Matlab/Python not add simply add a JIT compiler?\n",
    "\n",
    "- Yes ... see Cython, Numba and PyPy for Python. \n",
    "\n",
    "\n",
    "- But ... limited to specific built-in types? (Numba) or compatibility issues with existing Python ecosystem (PyPy)?\n",
    "\n",
    "- Toy problems from this presentation can probably be dealt with, but entire scientific computing packages ... ?\n",
    "\n",
    "- Matlab also does some sort of black box JIT compilation these days ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# So should you all switch to Julia today?\n",
    "\n",
    "Probably not. \n",
    "\n",
    "If you don't care about performance that much or rely heavily on certain Python packages (although they can be called from Julia) then maybe Julia is not worth your time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, Julia might be interesting if you do \"scientific computing stuff\" where\n",
    "- performance is important; and/or\n",
    "- you work on new implementations/techniques/whatever rather than being simply a user of existing software packages;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But be prepared because:\n",
    "- there definitely is a learning curve,\n",
    "- you will have to adjust your workflow to the language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Julia Resources\n",
    "\n",
    "- https://julialang.org\n",
    "- https://discourse.julialang.org\n",
    "- Anything by Chris Rackauckus (https://www.stochasticlifestyle.com)\n",
    "- Anything by Stefan Karpinski (https://www.youtube.com/watch?v=kc9HwsxE1OY)\n",
    "- Anything by Stephen G. Johnson (https://julialang.org/blog/2017/01/moredots)\n",
    "- https://julia.quantecon.org\n",
    "- Package development workflow https://www.youtube.com/watch?v=QVmU29rCjaA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
